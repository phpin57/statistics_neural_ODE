{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4a14ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "#from torchdiffeq import odeint_adjoint as odeint\n",
    "from scipy.linalg import expm\n",
    "from torchdiffeq import odeint\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2ba1ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dydt(y, t, A):\n",
    "    return torch.mm(y,A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bc13465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi_A(y,A):\n",
    "    return odeint(lambda t,x : dydt(x,t,A), y, torch.tensor([0., 1.]))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0c29990",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ODEFunc(torch.nn.Module):\n",
    "    def __init__(self, A):\n",
    "        super(ODEFunc, self).__init__()\n",
    "        self.A = torch.nn.Parameter(torch.tensor(A))\n",
    "        \n",
    "    def forward(self, t, y):\n",
    "        return dydt(y, t, self.A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36e67112",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralODE(torch.nn.Module):\n",
    "    def __init__(self, A_init):\n",
    "        super(NeuralODE, self).__init__()\n",
    "        self.func = ODEFunc(A_init)\n",
    "        self.hidden_layer = torch.nn.Linear(2, 10)\n",
    "        self.output_layer = torch.nn.Linear(10, 4)\n",
    "        \n",
    "    def forward(self, y):\n",
    "        y = self.hidden_layer(y)\n",
    "        y = torch.relu(y)\n",
    "        y = self.output_layer(y)\n",
    "        return y\n",
    "    \n",
    "    def get_A(self):\n",
    "        return self.func.A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8c9317c",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_true = torch.tensor([[1., 2.], [3., 4.]])\n",
    "training_losses={}\n",
    "frob_losses={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e9ab8267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [0., 2., 0., 0.],\n",
       "        [0., 0., 3., 0.],\n",
       "        [0., 0., 0., 4.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.diag(torch.Tensor([1,2,3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7020f04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, x_data,y_data,epochs=500, lr=0.05):\n",
    "    training_loss=[]\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = odeint(model.func, x_data, torch.tensor([0., 1.]), method='dopri5')\n",
    "        loss = criterion(y_pred, y_data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 20 == 0:\n",
    "            print(f\"Epoch {epoch}, Training Loss: {loss:.4f}\")\n",
    "            print(neural_ode.get_A())\n",
    "            training_loss.append(int(loss.detach().numpy().item()))\n",
    "    return training_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10650a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples=500\n",
    "\n",
    "x_data = torch.randn(n_samples, 2)\n",
    "y_data = phi_A(x_data,A_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e47a80a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_21764\\3190449401.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.A = torch.nn.Parameter(torch.tensor(A))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Training Loss: 15510.5742\n",
      "Parameter containing:\n",
      "tensor([[0.7300, 2.2300],\n",
      "        [2.7300, 4.4300]], requires_grad=True)\n",
      "Epoch 20, Training Loss: 12397.1807\n",
      "Parameter containing:\n",
      "tensor([[0.7475, 2.0835],\n",
      "        [2.7278, 4.2646]], requires_grad=True)\n",
      "Epoch 40, Training Loss: 12279.7734\n",
      "Parameter containing:\n",
      "tensor([[0.8932, 1.9817],\n",
      "        [2.8230, 4.1275]], requires_grad=True)\n",
      "Epoch 60, Training Loss: 12256.6338\n",
      "Parameter containing:\n",
      "tensor([[1.0370, 1.9492],\n",
      "        [2.9111, 4.0605]], requires_grad=True)\n",
      "Epoch 80, Training Loss: 12253.8535\n",
      "Parameter containing:\n",
      "tensor([[1.0998, 1.9457],\n",
      "        [2.9407, 4.0343]], requires_grad=True)\n",
      "Epoch 100, Training Loss: 12253.8643\n",
      "Parameter containing:\n",
      "tensor([[1.1080, 1.9513],\n",
      "        [2.9387, 4.0297]], requires_grad=True)\n",
      "Epoch 120, Training Loss: 12253.8018\n",
      "Parameter containing:\n",
      "tensor([[1.1021, 1.9544],\n",
      "        [2.9328, 4.0306]], requires_grad=True)\n",
      "Epoch 140, Training Loss: 12253.7930\n",
      "Parameter containing:\n",
      "tensor([[1.0993, 1.9545],\n",
      "        [2.9313, 4.0313]], requires_grad=True)\n",
      "Epoch 160, Training Loss: 12253.7920\n",
      "Parameter containing:\n",
      "tensor([[1.0995, 1.9541],\n",
      "        [2.9319, 4.0314]], requires_grad=True)\n",
      "Epoch 180, Training Loss: 12253.7920\n",
      "Parameter containing:\n",
      "tensor([[1.0997, 1.9539],\n",
      "        [2.9323, 4.0313]], requires_grad=True)\n",
      "Epoch 200, Training Loss: 12253.7920\n",
      "Parameter containing:\n",
      "tensor([[1.0996, 1.9540],\n",
      "        [2.9323, 4.0312]], requires_grad=True)\n",
      "Epoch 220, Training Loss: 12253.7920\n",
      "Parameter containing:\n",
      "tensor([[1.0995, 1.9541],\n",
      "        [2.9323, 4.0312]], requires_grad=True)\n",
      "Epoch 240, Training Loss: 12253.7920\n",
      "Parameter containing:\n",
      "tensor([[1.0995, 1.9541],\n",
      "        [2.9323, 4.0312]], requires_grad=True)\n",
      "Epoch 260, Training Loss: 12253.7920\n",
      "Parameter containing:\n",
      "tensor([[1.0994, 1.9541],\n",
      "        [2.9324, 4.0312]], requires_grad=True)\n",
      "Epoch 280, Training Loss: 12253.7920\n",
      "Parameter containing:\n",
      "tensor([[1.0993, 1.9542],\n",
      "        [2.9324, 4.0312]], requires_grad=True)\n",
      "Epoch 300, Training Loss: 12253.7920\n",
      "Parameter containing:\n",
      "tensor([[1.0992, 1.9542],\n",
      "        [2.9325, 4.0311]], requires_grad=True)\n",
      "Epoch 320, Training Loss: 12253.7920\n",
      "Parameter containing:\n",
      "tensor([[1.0991, 1.9542],\n",
      "        [2.9326, 4.0311]], requires_grad=True)\n",
      "Epoch 340, Training Loss: 12253.7920\n",
      "Parameter containing:\n",
      "tensor([[1.0991, 1.9543],\n",
      "        [2.9326, 4.0311]], requires_grad=True)\n",
      "Epoch 360, Training Loss: 12253.7920\n",
      "Parameter containing:\n",
      "tensor([[1.0990, 1.9543],\n",
      "        [2.9327, 4.0310]], requires_grad=True)\n",
      "Epoch 380, Training Loss: 12253.7920\n",
      "Parameter containing:\n",
      "tensor([[1.0989, 1.9544],\n",
      "        [2.9327, 4.0310]], requires_grad=True)\n",
      "Epoch 400, Training Loss: 12253.7920\n",
      "Parameter containing:\n",
      "tensor([[1.0988, 1.9544],\n",
      "        [2.9328, 4.0310]], requires_grad=True)\n",
      "Epoch 420, Training Loss: 12253.7920\n",
      "Parameter containing:\n",
      "tensor([[1.0987, 1.9545],\n",
      "        [2.9329, 4.0310]], requires_grad=True)\n",
      "Epoch 440, Training Loss: 12253.7920\n",
      "Parameter containing:\n",
      "tensor([[1.0986, 1.9545],\n",
      "        [2.9330, 4.0309]], requires_grad=True)\n",
      "Epoch 460, Training Loss: 12253.7920\n",
      "Parameter containing:\n",
      "tensor([[1.0984, 1.9546],\n",
      "        [2.9330, 4.0309]], requires_grad=True)\n",
      "Epoch 480, Training Loss: 12253.7920\n",
      "Parameter containing:\n",
      "tensor([[1.0983, 1.9546],\n",
      "        [2.9331, 4.0309]], requires_grad=True)\n",
      "Estimated A:\n",
      "Parameter containing:\n",
      "tensor([[1.0982, 1.9547],\n",
      "        [2.9332, 4.0308]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "neural_ode = NeuralODE(torch.tensor([[0.8,2.3],[2.8,4.5]]))\n",
    "\n",
    "training_loss=train_model(neural_ode, x_data,y_data)\n",
    "A_estimated = neural_ode.get_A()\n",
    "\n",
    "#ajout des r√©sultats pour chaque n_samples\n",
    "training_losses[n_samples]=training_loss\n",
    "frob_losses[n_samples]=np.linalg.norm((A_true-A_estimated).detach().numpy())\n",
    "\n",
    "print(f\"Estimated A:\\n{A_estimated}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b03f91a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{500: 0.13084218}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frob_losses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
